<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: linux | As a SW/Ops/DB Engineer]]></title>
  <link href="http://tech.riywo.com/blog/categories/linux/atom.xml" rel="self"/>
  <link href="http://tech.riywo.com/"/>
  <updated>2014-12-26T01:21:17+09:00</updated>
  <id>http://tech.riywo.com/</id>
  <author>
    <name><![CDATA[riywo]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Fluentd on Mesos + Docker + Marathon]]></title>
    <link href="http://tech.riywo.com/blog/2013/12/20/fluentd-on-mesos-plus-docker-plus-marathon/"/>
    <updated>2013-12-20T17:13:00+09:00</updated>
    <id>http://tech.riywo.com/blog/2013/12/20/fluentd-on-mesos-plus-docker-plus-marathon</id>
    <content type="html"><![CDATA[<p>I just tried to run Fluentd instances on Mesos + Docker + Marathon in Vagrant boxes. Here is the sample repository.</p>

<ul>
<li><a href="https://github.com/riywo/sample-fluentd-on-mesos-docker">riywo/sample-fluentd-on-mesos-docker</a></li>
</ul>


<p>The overview diagram:</p>

<p><img src="https://cacoo.com/diagrams/9XIEXwoUNUvOOuZ2-AB7C1.png" alt="diagram" /></p>

<!-- more-->


<h2>How?</h2>

<p>See the github README.md.</p>

<h2>What?</h2>

<h3>Fluentd</h3>

<ul>
<li><a href="http://fluentd.org/">Fluentd: Open Source Log Management</a></li>
</ul>


<p>Fluentd is one of log collector middleware. Most web companies in Japan use this for log collecting. td-agent is a package version of fluentd including ruby interpreter.</p>

<p>Some uses want to spin up multiple fluentd workers across many physical servers because fluentd only use one cpu core. Mesos is the right software to manage such situation.</p>

<h3>Mesos</h3>

<ul>
<li><a href="http://mesos.apache.org/">Apache Mesos</a></li>
</ul>


<p>Computer resource management software. You can combine many servers as a one &ldquo;virtual computer&rdquo; with Mesos. Mesos itself is just allocating resources, so you have to use frameworks to manage these resources.</p>

<h3>Marathon</h3>

<ul>
<li><a href="https://github.com/mesosphere/marathon">mesosphere/marathon</a></li>
</ul>


<p>Marathon is a framework on Mesos, which is like &ldquo;upstart for virtual computer&rdquo;. Marathon makes sure the number of running tasks, so if one of Mesos slave goes down, Marathon starts new instances on other slaves.</p>

<p>Marathon also manages port of instances. You can get the list of host:port of your applications just asking Marathon API; this is kind of service discovery.</p>

<h3>Docker</h3>

<ul>
<li><a href="https://www.docker.io/">Homepage - Docker: the Linux container engine</a></li>
</ul>


<p>LXC manager. You don&rsquo;t have to take care of server environment any more. Just create a docker container and commit it. Then, you can run the application anywhere you want. This is very convenient for computer cluster like Mesos.</p>

<p>Mesosphere provides a simple Mesos executor for docker. It runs docker container and bind ports, so you can connect containers from outside of the slave.</p>

<h3>HAProxy</h3>

<ul>
<li><a href="http://haproxy.1wt.eu/">HAProxy - The Reliable, High Performance TCP/HTTP Load Balancer</a></li>
</ul>


<p>Fluentd has http input interface, so I connect them with HAProxy running on Docker. First getting the list of host:port from Marathon, then generating config file of HAProxy. If the list is updated, just restart the HAProxy container.</p>

<h3>Elasticsearch, Kibana</h3>

<ul>
<li><a href="http://www.elasticsearch.org/">Open Source Distributed Real Time Search &amp; Analytics | Elasticsearch</a></li>
<li><a href="http://www.elasticsearch.org/overview/kibana/">Kibana | Overview | Elasticsearch</a></li>
</ul>


<p>Elasticsearch and Kibana is one of the best combination of storing logs and visualizing them.</p>

<p>Fluentd has pluggable input/output and there is Elasticsearch output plugin. I installed it in the fluentd docker image. Giving ES host:port to the container as environment variables, fluentd can connect the ES. I run ES and Kibana on Docker, too.</p>

<h2>Conclusion</h2>

<p>It was very interesting exercise for me. I&rsquo;d like to keep practicing Mesos, Docker, Marathon, Vagrant, whatever. I hope this sample helps you, too.</p>

<p>BTW, there were so much trouble especially Vagrant integration. <code>/etc/hosts</code> file is very tricky. I&rsquo;d like to know more reasonable way to manage Vagrant hosts information…</p>

<h2>References</h2>

<ul>
<li><a href="https://github.com/mesosphere/mesos-docker">mesosphere/mesos-docker</a></li>
<li><a href="http://mesosphere.io/2013/09/26/docker-on-mesos/">Mesosphere · Docker on Mesos</a></li>
<li><a href="http://techcrunch.com/2013/09/26/mesosphere-adds-docker-support-to-its-mesos-based-operating-system-for-the-data-center/">Mesosphere Adds Docker Support To Its Mesos-Based Operating System For The Data Center | TechCrunch</a></li>
<li><a href="http://www.slideshare.net/AishFenton/mesos-docker">Mesos ♥ Docker</a>

<ul>
<li><a href="http://www.youtube.com/watch?v=2MmnggSmTJo">▶ Docker ♥ Mesos - YouTube</a></li>
</ul>
</li>
<li><a href="http://typesafe.com/blog/play-framework-grid-deployment-with-mesos">Play Framework Grid Deployment with Mesos – Blog - Typesafe</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[chown with user's default group]]></title>
    <link href="http://tech.riywo.com/blog/2013/10/11/chown-with-users-default-group/"/>
    <updated>2013-10-11T12:55:00+09:00</updated>
    <id>http://tech.riywo.com/blog/2013/10/11/chown-with-users-default-group</id>
    <content type="html"><![CDATA[<p>You may have used <code>chown</code> command to change the ownership of files or directories like below.</p>

<pre><code>$ ls -l file
-rw-r--r--  1 root root  675 2013-09-23 23:23 file
$ sudo chown foo file
$ ls -l file
-rw-r--r--  1 foo root  675 2013-09-23 23:23 file
</code></pre>

<p>But this is not good because group of <code>file</code> is still <code>root</code>. Most case, you want to set it the default(login) group of the user.</p>

<pre><code>$ id foo
uid=1010(foo) gid=1009(foo) groups=1009(foo)
</code></pre>

<p>In this case, you want to set it <code>foo</code>. For that, I used a command below.</p>

<pre><code>$ chown foo:foo file
$ ls -l file
-rw-r--r--  1 foo foo  675 2013-09-23 23:23 file
</code></pre>

<p>Not bad. But you have to know the default group of the user. It is not always same as the user name.</p>

<!-- more -->


<p>So, here is the best way. Just add <code>:</code> after the user name.</p>

<pre><code>$ sudo chown foo: file
$ ls -l file
-rw-r--r--  1 foo foo  675 2013-09-23 23:23 file
</code></pre>

<p>Wow! This is super easy. See also <code>man chmod</code></p>

<pre><code>… If a colon but no group name follows the user name, that user is made the owner of the files and the group of the files is changed to that user's login group. …
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[fcache - file cache for parallel processes]]></title>
    <link href="http://tech.riywo.com/blog/2013/05/10/fcache-file-cache-for-parallel-processes/"/>
    <updated>2013-05-10T01:46:00+09:00</updated>
    <id>http://tech.riywo.com/blog/2013/05/10/fcache-file-cache-for-parallel-processes</id>
    <content type="html"><![CDATA[<p>以前からたまーにこういうのがあるとうれしいケースがあるなぁと思ってたので作りました。</p>

<ul>
<li><a href="https://github.com/riywo/fcache">riywo/fcache · GitHub</a></li>
</ul>


<p>どういうものかというと、こういう感じで何かstdoutに吐き出すコマンドの前に<code>fcache EXPIRE_SEC</code>というのを付け足して実行すると、初回はコマンドを実行して結果をファイルに保存しつつstdoutにも出力します。</p>

<pre><code>$ fcache 10 curl -s example.com
hoge
</code></pre>

<p>次に、同じ<code>fcache</code>コマンドを叩くと、保存されているキャッシュファイルの時刻を見て、expire時刻を過ぎてなければ単にそのファイルの中身をstdoutに吐き出して終了します。</p>

<pre><code>$ fcache 10 curl -s example.com # 実際はcurlは実行されない
hoge
</code></pre>

<p>expire時刻を過ぎていれば初回と同じ動きをしてキャッシュを更新してくれます。<code>flock</code>を使って、読み込みだけなら共有ロックで並列に、書き込みが発生する時には排他ロック、みたいな処理をしてます(が何分まともな排他制御書いたことないのできっとバグってます。。。)</p>

<!-- more -->


<h2>何の役に立つの？</h2>

<p>特に監視の処理の中で、ほぼ同時に並列で1つのAPIを叩く監視項目があった時に、みんなが同じAPIを叩くのは非効率だなぁと思った時に効果があります(つまりニッチ)。何も気にせず<code>fcache</code>コマンドを並列に実行すれば、最初の人がAPIを叩いてキャッシュしてくれて、あとの人はキャッシュを利用してくれます。</p>

<p>例えばZabbixという監視ソフトには<code>UserParameter</code>というagent側でコマンドを実行して数値を返す、みたいなのが定義できます。</p>

<pre><code>$ curl -s localhost
aaa 1
bbb 2
ccc 3

$ cat /path/to/zabbix_agentd.conf
UserParameter=example.key[*],curl -s localhost | grep $1 | cut -f 2
</code></pre>

<p>上の様な設定をしたサーバがあったとすると、<code>zabbix_get</code>で<code>aaa</code>,<code>bbb</code>,<code>ccc</code>の値が取れます。</p>

<pre><code>$ zabbix_get -s server -k example.key[aaa]
1
$ zabbix_get -s server -k example.key[bbb]
2
$ zabbix_get -s server -k example.key[ccc]
3
</code></pre>

<p>ただし、これだと3回<code>curl</code>が呼ばれます。もし<code>curl</code>を減らしたいなら、1つのitemでスクリプトを実行してその中で1回だけ<code>curl</code>してから全てのキーについて<code>zabbix_sender</code>で送る、とかも考えられます。</p>

<pre><code>$ cat /path/to/zabbix_agentd.conf
UserParameter=example.key,/path/to/script # 中でzabbix_senderを複数実行
</code></pre>

<p><code>fcache</code>を使うとシンプルに実現できます。これならキャッシュの有効期間中は<code>curl</code>は叩かれませんし、configも素直です。</p>

<pre><code>$ cat /path/to/zabbix_agentd.conf
UserParameter=example.key[*],fcache 10 curl -s localhost | grep $1 | cut -f 2
</code></pre>

<h2>おわりに</h2>

<p>適当に作った上に、自分で使ってるわけでもないので自己責任でご利用下さい。こういうコンセプトがあってもおもしろいよねという提案がしたかったのと、ちょうどpythonの勉強がしたかったので、自分的には満足です。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mruby on MIPS in PQI Air Pen]]></title>
    <link href="http://tech.riywo.com/blog/2013/05/07/mruby-on-mips-in-pqi-air-pen/"/>
    <updated>2013-05-07T07:40:00+09:00</updated>
    <id>http://tech.riywo.com/blog/2013/05/07/mruby-on-mips-in-pqi-air-pen</id>
    <content type="html"><![CDATA[<p>moyashi さんの記事を読んで以来、ずっと欲しかったPQI Airシリーズなんですが、USのAmazonでは売ってなかったり無駄に高かったりして二の足を踏んでました。ある日、郵便局を使うと数百円で荷物が送れることが分かったので、日本のAmazonで買って実家に発送して送ってもらうことでついにゲットしました。</p>

<ul>
<li><a href="http://hitoriblog.com/?p=12627">ひとりぶろぐ » デジカメ内部でRubyを動かす狂気！無線LAN内蔵SDカードアダプタPQI Air Cardの間違った使い方</a></li>
<li><a href="http://hitoriblog.com/?p=15926">ひとりぶろぐ » ポケット無線LANルータの新顔PQI Air Penの著しく間違った使い方</a></li>
</ul>


<p>ただ、Cardの方を動かせるmicroSDを持ってなかったので、今はPenでちょっと遊んでみただけです。何をやったかというと、<code>mruby</code>を動かしてみました。CRubyはちょっと動かせる自信なかったですが、最初から組み込み向けの<code>mruby</code>なら簡単かなぁと思ってやってみたら簡単でした。</p>

<!-- more -->


<h2>Cross Compile</h2>

<p>PQI AirのハードウェアはCPUがMIPSで、使い慣れているx86/x86_64とは違います。ので単にいつもLinuxで使ってるバイナリをコピーしてもダメです。</p>

<pre><code># cat /proc/cpuinfo
system type             : Atheros AR9330 (Hornet)
processor               : 0
cpu model               : MIPS 24Kc V7.4
BogoMIPS                : 232.96
wait instruction        : yes
microsecond timers      : yes
tlb_entries             : 16
extra interrupt vector  : yes
hardware watchpoint     : yes, count: 4, address/irw mask: [0x0000, 0x0c68, 0x0ff8, 0x0393]
ASEs implemented        : mips16
shadow register sets    : 1
core                    : 0
VCED exceptions         : not available
VCEI exceptions         : not available
</code></pre>

<p>さすがにここでコンパイルするのは、その環境を準備するところで挫折しそうなのでクロスコンパイル(別のアーキテクチャ用のバイナリをコンパイルする)をしました。</p>

<p>やり方はmoyashiさんが紹介されているSourcery CodeBenchというツールチェインを使って静的リンクでコンパイルしただけです。楽チン。</p>

<ul>
<li><a href="http://www.mentor.com/embedded-software/sourcery-tools/sourcery-codebench/editions/lite-edition/">Sourcery CodeBench Lite Edition - Mentor Graphics</a></li>
</ul>


<p>Macで動かすにはこれ自体をセルフビルドする必要があったので萎えて、Vagrantで適当に32bit Linuxを起動して、インストール。適当に<code>PATH</code>を通しておきます。以下は<code>Vagrantfile</code>の例。</p>

<pre><code>$ cat Vagrantfile
Vagrant.configure("2") do |config|
  config.vm.box = "precise32"
  config.vm.box_url = "http://files.vagrantup.com/precise32.box"
  config.vm.provision :shell, :inline =&gt; "apt-get install build-essential -y"
end
$ vagrant up
$ vagrant ssh
</code></pre>

<p><code>mruby</code>は最近ビルド方法が変わったらしく、rubyが必要なのでこれも適当に。Vagrantのboxだと大抵入ってるかな。あと必要なパッケージも適当に。Vagrantfileに書いといてもいいね。</p>

<pre><code>$ sudo apt-get install bison git
</code></pre>

<p>これで適当にクロスコンパイルの準備ができました。</p>

<h2>make mruby</h2>

<p>とりあえずコード取ってきます。</p>

<pre><code>$ git clone https://github.com/mruby/mruby.git
$ cd mruby
</code></pre>

<p><code>mruby</code>は<code>build_config.rb</code>というファイルでコンパイルの方法を色々変えられます(多分)。今回は以下を追加してみました。意味は簡単でMIPS用の<code>gcc</code>や<code>ar</code>が先ほどのSoucery CodeBenchに入ってるので、それを適当なオプションとともに指定してるだけです。</p>

<pre><code>MRuby::CrossBuild.new('pqi-air') do |conf|
  toolchain :gcc

  conf.gembox 'default'
  conf.cc.command = "mips-linux-gnu-gcc"
  conf.cc.flags &lt;&lt; %w(-g -O2 -Wall -static -march=24kc)
  conf.linker.command = "mips-linux-gnu-gcc"
  conf.linker.flags &lt;&lt; %w(-s -static)
  conf.archiver.command = "mips-linux-gnu-ar"
end
</code></pre>

<p>もともとある<code>MRuby::Build</code>の方を消すと<code>undefined method 'build_dir' for nil:NilClass</code>なるエラーになってしまうのでそれも残しておきます(何かやり方間違ってる気が。。。)</p>

<p>あとは<code>make</code>したらできあがり。</p>

<pre><code>$ make
ruby ./minirake
(in /home/vagrant/mruby)

Build summary:

================================================
      Config Name: pqi-air
 Output Directory: build/pqi-air
         Binaries: mrbc
    Included Gems:
             mruby-sprintf
             mruby-print
             mruby-math
             mruby-time
             mruby-struct
             mruby-enum-ext
             mruby-string-ext
             mruby-numeric-ext
             mruby-array-ext
             mruby-hash-ext
             mruby-range-ext
             mruby-proc-ext
             mruby-symbol-ext
             mruby-random
             mruby-bin-mirb
               - Binaries: mirb
             mruby-bin-mruby
               - Binaries: mruby
================================================

$ file build/pqi-air/bin/*
build/pqi-air/bin/mirb:  ELF 32-bit MSB executable, MIPS, MIPS32 rel2 version 1, statically linked, for GNU/Linux 2.6.12, with unknown capability 0x41000000 = 0xf676e75, with unknown capability 0x10000 = 0x70401, stripped
build/pqi-air/bin/mrbc:  ELF 32-bit MSB executable, MIPS, MIPS32 rel2 version 1, statically linked, for GNU/Linux 2.6.12, with unknown capability 0x41000000 = 0xf676e75, with unknown capability 0x10000 = 0x70401, stripped
build/pqi-air/bin/mruby: ELF 32-bit MSB executable, MIPS, MIPS32 rel2 version 1, statically linked, for GNU/Linux 2.6.12, with unknown capability 0x41000000 = 0xf676e75, with unknown capability 0x10000 = 0x70401, stripped
</code></pre>

<h2>実行！</h2>

<p>あとは出来上がったフォルダ一式(と言いつつ静的リンクした実行ファイルしか試してませんが。。。)をPQI Air Penに挿したSDカードにコピーしたら実行！</p>

<pre><code># ./mruby -e 'p 1+1'
2
# ./mirb
mirb - Embeddable Interactive Ruby Shell

This is a very early version, please test and report errors.
Thanks :)

&gt; a = {:foo =&gt; 1, :bar =&gt; 2}
 =&gt; {:foo=&gt;1, :bar=&gt;2}
&gt; a.each { |k,v| p "#{k} =&gt; #{v}" }
"foo =&gt; 1"
"bar =&gt; 2"
 =&gt; {:foo=&gt;1, :bar=&gt;2}
</code></pre>

<p>感動的ですね、こんなちっこいマシンの上でrubyが動くなんて。<code>mirb</code>は<code>readline</code>がないせいか、カーソルキー効かなくて不便ですが。。。</p>

<p><code>mruby</code>のことは実はさっぱり分かってないのですが、色々楽しめそうです。興味ある方はぜひ遊んでみて下さい or 遊び方教えて下さい。</p>

<iframe src="http://rcm-jp.amazon.co.jp/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=futuristamazo-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=B00BNAST0O" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>




<iframe src="http://rcm-jp.amazon.co.jp/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=futuristamazo-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=B009HF63GE" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[webtail + ncat = simple log monitoring!]]></title>
    <link href="http://tech.riywo.com/blog/2013/04/23/webtail-plus-ncat-equals-simple-log-monitoring-slash/"/>
    <updated>2013-04-23T18:58:00+09:00</updated>
    <id>http://tech.riywo.com/blog/2013/04/23/webtail-plus-ncat-equals-simple-log-monitoring-slash</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/r7kamura/webtail">webtail</a> is a super simple log monitoring tool. You can monitor a log streaming on a server via your web browser.</p>

<p>I wanted to monitor multi servers log, so I tried <code>ncat</code> in <code>mmap</code>. <code>ncat</code> supports multi sessions.</p>

<ul>
<li><a href="http://nmap.org/ncat/">Ncat - Netcat for the 21st Century</a></li>
</ul>


<!-- more -->


<p>Here is an example.</p>

<pre><code>## monitor server
mon&gt; ncat -l -k 10000 | webtail

## web servers
web1&gt; tail -F access_log | sed -e 's/^/web1 /' | nc mon 10000
web2&gt; tail -F access_log | sed -e 's/^/web2 /' | nc mon 10000
web3&gt; tail -F access_log | sed -e 's/^/web3 /' | nc mon 10000
</code></pre>

<p>You can monitor all web servers logs with a single web page.</p>

<p>Enjoy!</p>
]]></content>
  </entry>
  
</feed>

<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: docker | As a SW/Ops/DB Engineer]]></title>
  <link href="http://tech.riywo.com/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://tech.riywo.com/"/>
  <updated>2014-12-26T01:21:17+09:00</updated>
  <id>http://tech.riywo.com/</id>
  <author>
    <name><![CDATA[riywo]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Fluentd on Mesos + Docker + Marathon]]></title>
    <link href="http://tech.riywo.com/blog/2013/12/20/fluentd-on-mesos-plus-docker-plus-marathon/"/>
    <updated>2013-12-20T17:13:00+09:00</updated>
    <id>http://tech.riywo.com/blog/2013/12/20/fluentd-on-mesos-plus-docker-plus-marathon</id>
    <content type="html"><![CDATA[<p>I just tried to run Fluentd instances on Mesos + Docker + Marathon in Vagrant boxes. Here is the sample repository.</p>

<ul>
<li><a href="https://github.com/riywo/sample-fluentd-on-mesos-docker">riywo/sample-fluentd-on-mesos-docker</a></li>
</ul>


<p>The overview diagram:</p>

<p><img src="https://cacoo.com/diagrams/9XIEXwoUNUvOOuZ2-AB7C1.png" alt="diagram" /></p>

<!-- more-->


<h2>How?</h2>

<p>See the github README.md.</p>

<h2>What?</h2>

<h3>Fluentd</h3>

<ul>
<li><a href="http://fluentd.org/">Fluentd: Open Source Log Management</a></li>
</ul>


<p>Fluentd is one of log collector middleware. Most web companies in Japan use this for log collecting. td-agent is a package version of fluentd including ruby interpreter.</p>

<p>Some uses want to spin up multiple fluentd workers across many physical servers because fluentd only use one cpu core. Mesos is the right software to manage such situation.</p>

<h3>Mesos</h3>

<ul>
<li><a href="http://mesos.apache.org/">Apache Mesos</a></li>
</ul>


<p>Computer resource management software. You can combine many servers as a one &ldquo;virtual computer&rdquo; with Mesos. Mesos itself is just allocating resources, so you have to use frameworks to manage these resources.</p>

<h3>Marathon</h3>

<ul>
<li><a href="https://github.com/mesosphere/marathon">mesosphere/marathon</a></li>
</ul>


<p>Marathon is a framework on Mesos, which is like &ldquo;upstart for virtual computer&rdquo;. Marathon makes sure the number of running tasks, so if one of Mesos slave goes down, Marathon starts new instances on other slaves.</p>

<p>Marathon also manages port of instances. You can get the list of host:port of your applications just asking Marathon API; this is kind of service discovery.</p>

<h3>Docker</h3>

<ul>
<li><a href="https://www.docker.io/">Homepage - Docker: the Linux container engine</a></li>
</ul>


<p>LXC manager. You don&rsquo;t have to take care of server environment any more. Just create a docker container and commit it. Then, you can run the application anywhere you want. This is very convenient for computer cluster like Mesos.</p>

<p>Mesosphere provides a simple Mesos executor for docker. It runs docker container and bind ports, so you can connect containers from outside of the slave.</p>

<h3>HAProxy</h3>

<ul>
<li><a href="http://haproxy.1wt.eu/">HAProxy - The Reliable, High Performance TCP/HTTP Load Balancer</a></li>
</ul>


<p>Fluentd has http input interface, so I connect them with HAProxy running on Docker. First getting the list of host:port from Marathon, then generating config file of HAProxy. If the list is updated, just restart the HAProxy container.</p>

<h3>Elasticsearch, Kibana</h3>

<ul>
<li><a href="http://www.elasticsearch.org/">Open Source Distributed Real Time Search &amp; Analytics | Elasticsearch</a></li>
<li><a href="http://www.elasticsearch.org/overview/kibana/">Kibana | Overview | Elasticsearch</a></li>
</ul>


<p>Elasticsearch and Kibana is one of the best combination of storing logs and visualizing them.</p>

<p>Fluentd has pluggable input/output and there is Elasticsearch output plugin. I installed it in the fluentd docker image. Giving ES host:port to the container as environment variables, fluentd can connect the ES. I run ES and Kibana on Docker, too.</p>

<h2>Conclusion</h2>

<p>It was very interesting exercise for me. I&rsquo;d like to keep practicing Mesos, Docker, Marathon, Vagrant, whatever. I hope this sample helps you, too.</p>

<p>BTW, there were so much trouble especially Vagrant integration. <code>/etc/hosts</code> file is very tricky. I&rsquo;d like to know more reasonable way to manage Vagrant hosts information…</p>

<h2>References</h2>

<ul>
<li><a href="https://github.com/mesosphere/mesos-docker">mesosphere/mesos-docker</a></li>
<li><a href="http://mesosphere.io/2013/09/26/docker-on-mesos/">Mesosphere · Docker on Mesos</a></li>
<li><a href="http://techcrunch.com/2013/09/26/mesosphere-adds-docker-support-to-its-mesos-based-operating-system-for-the-data-center/">Mesosphere Adds Docker Support To Its Mesos-Based Operating System For The Data Center | TechCrunch</a></li>
<li><a href="http://www.slideshare.net/AishFenton/mesos-docker">Mesos ♥ Docker</a>

<ul>
<li><a href="http://www.youtube.com/watch?v=2MmnggSmTJo">▶ Docker ♥ Mesos - YouTube</a></li>
</ul>
</li>
<li><a href="http://typesafe.com/blog/play-framework-grid-deployment-with-mesos">Play Framework Grid Deployment with Mesos – Blog - Typesafe</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mesos introduction 1]]></title>
    <link href="http://tech.riywo.com/blog/2013/09/27/mesos-introduction-1/"/>
    <updated>2013-09-27T00:53:00+09:00</updated>
    <id>http://tech.riywo.com/blog/2013/09/27/mesos-introduction-1</id>
    <content type="html"><![CDATA[<p>Today, Mesosphere released an important milestone. I really desired this integration.</p>

<ul>
<li><a href="http://mesosphere.io/2013/09/26/docker-on-mesos/">Mesosphere · Docker on Mesos</a></li>
</ul>


<p>Now, we can manage our &ldquo;Computers as an OS&rdquo;.</p>

<ul>
<li>Kernel

<ul>
<li><a href="http://mesos.apache.org/">Mesos</a></li>
</ul>
</li>
<li>Process

<ul>
<li><a href="https://www.docker.io/">Docker</a></li>
</ul>
</li>
<li>Init

<ul>
<li><a href="https://github.com/mesosphere/marathon">Marathon</a></li>
</ul>
</li>
<li>Cron

<ul>
<li><a href="https://github.com/airbnb/chronos">Chronos</a></li>
</ul>
</li>
</ul>


<!-- more -->


<p>I would like to learn this new generation &ldquo;OS&rdquo;, so I started to play with Mesos. Mesosphere is a great company and they built packages of Mesos and Marathon. Building Mesos and tools are most painful part of this ecosystem, but now we can super easily start to use Mesos and Marathon. Thanks, Mesosphere:)</p>

<p>I use AWS for Mesos cluster. At first, I created a m1.small instance for a master of Mesos, Zookeeper and Marathon. I use EC2-Classic.</p>

<ul>
<li>AMI

<ul>
<li>Ubuntu Server 13.04</li>
</ul>
</li>
<li>Security Group

<ul>
<li>From any src IP

<ul>
<li>22(ssh)</li>
<li>2181(zk)</li>
<li>5050(mesos master)</li>
<li>5051(mesos slave)</li>
<li>8080(marathon)</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>And I set user-data as an initial setup script:</p>

<pre><code>#!/bin/bash
curl -fL https://raw.github.com/mesosphere/mesos-docker/master/bin/mesos-docker-setup | bash
echo manual &gt;&gt; /etc/init/mesos-slave.conf
reboot
</code></pre>

<p>After the instance is ready, you can access Mesos(5050) and Marathon(8080) from your browser. I associated an EIP to the master.</p>

<p>Then, I requested 10 spot instances for slaves. Same type(m1.small), same AMI, same security group, and user-data:</p>

<pre><code>#!/bin/bash
curl -fL https://raw.github.com/mesosphere/mesos-docker/master/bin/mesos-docker-setup | bash
echo manual &gt;&gt; /etc/init/mesos-master.conf
echo manual &gt;&gt; /etc/init/marathon.conf
echo manual &gt;&gt; /etc/init/zookeeper.conf
echo 'zk://YOUR_MASTER_EIP:2181/mesos' &gt; /etc/mesos/zk
reboot
</code></pre>

<p>After a while, you can see 10 slaves, 10 CPUs and 6GB Mem on your Mesos dashboard! Wow! This is your new &ldquo;OS&rdquo;!</p>

<p>Now you can run ANY process using Mesosphere&rsquo;s Mesos, Marathon and Docker integration. Why don&rsquo;t you request Redis processes to your Marathon?</p>

<pre><code>$ http POST http://YOUR_MASTER_EIP:8080/v1/apps/start \
          id=multidis instances=2 mem=512 cpus=0.5 \
          executor=/var/lib/mesos/executors/docker \
          cmd='johncosta/redis'
</code></pre>

<p>This request will start 2 tasks and use 1 CPU and 1GB Mem. You can scale it very easily. Awesome…, awesome…</p>

<h2>Next step</h2>

<ul>
<li>Build Chronos</li>
<li>Run Chronos on Marathon</li>
<li>Create Docker image and run it on Marathon</li>
<li>Integration with <a href="https://github.com/coreos/etcd">etcd</a>, or something

<ul>
<li>Configuration of 12factor app</li>
</ul>
</li>
<li>Integration with <a href="http://ceph.com/">Ceph</a> or other storage

<ul>
<li>For virtual storage</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Private PaaS]]></title>
    <link href="http://tech.riywo.com/blog/2013/09/08/private-paas/"/>
    <updated>2013-09-08T02:24:00+09:00</updated>
    <id>http://tech.riywo.com/blog/2013/09/08/private-paas</id>
    <content type="html"><![CDATA[<p>作りたいなーと漠然と思ってるアイデア。自分用メモなので色々省略してますので、興味ある人がいれば詳しく話します。</p>

<ul>
<li>基本コンセプト

<ul>
<li>Herokuライクなデプロイ</li>
<li>壊れにくい</li>
<li>開発が運用コスト管理</li>
</ul>
</li>
<li>技術トピック

<ul>
<li>12factor</li>
<li>Docker</li>
<li>Mesos</li>
</ul>
</li>
</ul>


<!-- more -->


<h2>基本コンセプト</h2>

<p>よくある話で、開発者が自由にサーバを足し引きできたら楽だよね、という発想をもうちょっと現実的に意味のあるものにしてみた。単にgit pushでアプリ起動、くらいだったらdokkuとかDeisとか使えばなんもせんでもできる。けどそれだけだと、じゃあそのサーバの面倒は？とかリソースの割り当ては？とか、本質的に面倒な問題は片付かない。</p>

<p>ので、自由に計算機資源を使える代わりに、使う分のお金は自分で払ってね、というアイデアを考えた。普通にPaaS使うなら当たり前なんだけど、社内とかになると、余ってるサーバ使おう、共有部門の負担で、運用は誰かよろしく、みたいな感じになりがち。そうじゃなくて、自分達が使う分をちゃんとお金負担して使えば、チューニングも自分達でやらなきゃって思うし、コスト感覚が強くなると思う。</p>

<p>開発と運用を分けることで、確実に開発スピードは落ちる。落ちるから安定するとも言える。開発スピードを落とさず、お金かければある程度はスケールさせて逃げられるような共通基盤、あったらいいなぁ、ということで考えた結果、インフラ屋さんほとんど要らない感じにしたいなと思った。</p>

<h3>Herokuライクなデプロイ</h3>

<p>まぁこれは言うまでもなく。upstartとかdaemontoolsのrunスクリプトなんて、毎度書くのはDRYじゃない。デプロイしてアプリ起動までは共通的に自動化すべき。そうでなきゃ、結局サーバの管理コストが果てしなくなる。</p>

<h3>壊れにくい</h3>

<p>環境の構築が必要な時点で、壊れる可能性が非常に上がる。各種パッケージマネージャでバージョン固定しないと、とか。だったら、Dockerで稼働環境を丸っと固めて置くのがよい。デプロイもimageをダウンロードして起動するだけでシンプル。</p>

<h3>開発が運用コスト管理</h3>

<p>キャパシティプランニングも開発チームがやろう。でも、例えば開発チームが複数のサービスを1つのサーバクラスタで動かしたいとしたら、プランニングがとても面倒。だからといって、1サービス1クラスタとかにすると無駄が多くなりそう。Mesos使ってリソース管理すると、一段抽象化できるので計算しやすそうだし、足し引き簡単そう。</p>

<h2>技術トピック</h2>

<h3>12factor</h3>

<p>そもそもアプリの作りが12factor的な感じになってないと色々やりづらそう。特にconfigはオレオレにあのファイルやこのファイル読んで、とかなじゃくて、全部環境変数にしてしまう。</p>

<h3>Docker</h3>

<p>Docker imageはサービスごとに違っても、なんか共通の使っても、どっちでもいい。いつ誰がどこで起動しても同じ環境になるのがうれしい。その環境自体の記述はDockerfileで工夫する感じかな。ソースコードはbind mountすれば良さそう。</p>

<p>これやると開発環境と本番環境の差異が無くなるので多分うれしい人が多い。他には、新入社員の環境構築も一瞬、CIとかも環境構築に時間使わない、最初はEC2で大きくなったらオンプレでというのが超簡単、などなど。</p>

<p>デプロイはアプリケーションのリビジョンとそれが使うDocker imageのリビジョンをセットにする。ローカルのファイルシステムは使ってもいいけど、いつか消えるのでそういう用途に使わない(Herokuと同じ)。</p>

<p>もう一つ利点は、人気無くなったサービスとかを引き取る人が、何も調べずとも環境作れるので、とりあえず何の更新もせずに動かしておくだけのサービスの障害とかに時間使うことがほとんど無くなる。</p>

<h3>Mesos</h3>

<p>チームとかの単位でMesosクラスタ持つ。そのクラスタの料金を負担する。高負荷やバグをクラスタ増強でしのぎたければお金を積むか他から借りる。インフラ屋さんは全社のMesosクラスタ用のサーバの余剰を管理するだけでよし（ネットワーク資源除く）。開発側はMesosクラスタさえ持ってれば、あとはその資源の尽きない限りにおいて、自由に計算機資源を使えるので、インフラ屋さんにお伺いをたてる必要なくなる。EC2使うなら何も気にする必要ない、お金さえあれば。</p>

<p>動きはMesosがDockerを起動する感じMesosphereの人がそういうの作るって言ってたので待ってる。Marathon使えばdaemonも管理できそう。Chronos使えばcron駆逐できそう。</p>

<p>あとインフラ屋さんもDocker使って好きな監視エージェントとかをばらまける。こちらもイチイチ開発側にお伺いたてる必要ないので楽。共通的に使えるツールの開発と適応の速度上げられそう。</p>

<h2>課題</h2>

<p>データベースは要検討。Mesosにしてもいいのかもしれないし、そこはRDSとかみたいな外部サービスを使うかインフラ屋さんが同じようなインタフェースを作って責任持つのがいいのかもしれない。</p>

<p>ログ収集や監視は共通的に同じの入れてもいいかもだけど、そうすると今度はそれの更新スピードが落ちるので、Mesosで簡単に入れられるような基盤整備するだけがいいのかも。面倒くさがりは用意されたまま使えばいいし、手を入れたければ自分のところで勝手に変えてしまえばいい。</p>

<p>チューニングとかをインフラ屋さんが担ってたとしたら、そういう人を各サービスで抱えるか、もしくはそういう専門部隊として再編成すると良さそう。ナレッジとライブラリ・ツールの共有ができるようにすることが大事。</p>

<h2>まとめ</h2>

<p>お金で解決できるところはお金で解決して、なるべく時間の無駄を無くして開発スピードを上げるにはどうしたらいいかなということで考えた結果、開発側が運用コスト負担すればいいのではという結論になった。どうしても運用コストだけを見てる人と開発スピードだけを見てる人の価値観は合わないので、同じ人がやるべきかなと。</p>

<p>ただ、これやるぐらいなら各チームが勝手にHeroku使えばいいのでは？という気もするので、実装する気力は全然起きてない。誰かが作ってくれるのを待ってる。</p>
]]></content>
  </entry>
  
</feed>
